Here's a summary of what we discussed yesterday:

 

- Would you use a Primary-Backup replication scheme in a geographically distributed system, such as PNUTS or TAO?

 

A typical Primary-Backup replication scheme (cf. Lectures 8 & 12) is sensitive to late acknowledgements. When a client request arrives at the primary, the primary forwards the request to the backups and waits for acknowledgments from all backups. This is to make sure that f+1 servers (including the primary) have received the request before replying to the client. If a single acknowledgement is delayed, for some reason, the delay is added to the end-to-end latency of the request. In a system like PNUTS or TAO, where replicas are geographically distributed, acknowledgments go over the internet and will make the aforementioned problem even worse.

 

- Would you use a Raft-based replication scheme in a geographically distributed system, such as PNUTS or TAO?

 

Raft has redundancy (i.e. more servers) compared to a Primary-Backup replication scheme and the leader exchanges messages with all these servers, even if there are no client requests (e.g. when the leader sends periodic heartbeats). As a result, a Raft-based service will consume more network bandwidth compared to a Primary-Backup replication approach. In addition, heartbeat delays over a wide-area network will most likely trigger frequent re-elections, making the replication service unavailable for considerable periods of time.

 

- PNUTS and TAO use Pub/Sub systems to update geographically distributed replicas. What are the particular features of Pub/Syb systems that make them appealing in this setting?

 

The Pub/Sub system:

 

* updates all slave replicas asynchronously (off the critical-path of the client request)

* provides more flexibility (e.g. it is easier to change the master's location at runtime) 

* requires fewer messages amongst remote replicas (e.g. no frequent heartbeats over the internet)

* guarantees message delivery even in the case of failures

 

- Raft-based vs Primary-Backup replication: Would you prefer one approach over the other?

 

In general, the decision depends on many factors. Below are some points that can help you make the right choice:

 

* [Implementation] Raft seems more difficult to implement compared to a Primary-Backup replication scheme. On the other hand, many battle-tested Raft (and Paxos) implementations exist in the wild.

 

* [Redundancy] Raft requires more resources (servers) than a Primary-Backup replication scheme. To tolerate f failures, Raft-based replication requires 2f+1 servers whereas Primary-Backup replication requires f+1 servers. Servers are usually cheap commodity machines, however, If the top priority is to keep the number of servers (and, thus, the number of exchanged messages) low, then Primary-Backup replication is the way to go.

 

* [Latency/Throughput] The latency of a Primary-Backup replication scheme depends on the slowest of the f backup acknowledgments. Raftâ€™s latency of serving requests depends on the median latency of the 2f acknowledgements, as the leader only waits for f (out of 2f) followers to decide whether it can commit a request and reply back to the client. If redundancy (i.e. using 2f instead of f servers) is likely to improve the median latency of acknowledgements at steady state (e.g. because some servers reply faster than others), then a Raft-based service is expected to perform better (in terms of latency and throughput).

 

* [Availability] Primary-Backup and Raft-based replication services have similar periods of unavailability. A Primary-Backup replication scheme becomes unavailable when the primary fails and until the rest of the servers agree on the new primary. A Raft-based service is unavailable during leader elections.  

 

* [Scalability] Based on what we have discussed so far, it is not clear which approach scales better with respect to the incoming load. In fact, the primary (in Primary-Backup) and the leader (in Raft) are single nodes and can become bottlenecks in case the incoming load increases. One approach to scale out is to partition client requests across different Primary-Backup (resp. Raft-based) replication services, each one of which will operate in parallel and independently from the rest of the services. The tradeoff here is that you need N times more servers to tolerate the same amount of f failures, where N is the number of replication services.